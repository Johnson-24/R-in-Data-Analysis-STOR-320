---
title: "Final Paper"
author: "stor 320.01 Group 5"
date:  "`r format(Sys.time(), '%B %d, %Y')`"
output: html_document
---
# INTRODUCTION
```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(generics)
library(modelr)       #Helpful Functions in Modeling
library(xtable)
library(purrr)
library(broom)
library(class)
library(kableExtra)
library(readr)
library(tidyr)
library(glmnet)
library(tibble)

```


FIFA 20 is a video game that simulates football (soccer) games. This is a very popular game that is played all over the world. The game uses real players that you can choose form for your team. They all have different strengths and weaknesses and stats listed. FIFA 20 is a game with many interesting insights into real life players and football games. We, Group 5, thought it would be a good fit as we can see important influences on the game both on the field but also in the virtual atmosphere.

Our first question is which model and its variables best predict the variable composure? Our group thinks this is an interesting question, as composure can tell us a lot about a player. With composure we can see how comfortable a player is on the field. This is a good indication of the skill and experience a player possesses. This can also demonstrate how reliable or consistent a player will be during a game.

Our second question is can we predict the Wage of a player by looking at their skill level, position, defending rating, and their  shooting rating? (variables: skill_moves, position, and work_rate, defending, shooting). Wage is a very important variable for understanding a player's value. We can see how much a team is willing to invest in that player. It also is a good indicator for what the most desirable traits are in a player.

# DATA
Our dataset includes ratings and other details of all outfield players(excluding goalkeepers who have a different rating system) featured in FIFA 20, there are 29 different variables with player information like nationality and clubs and various aspects of ratings ranging from overall rating, shooting, passing, and dribbling; all the way to penalty kicks and composure.

Since FIFA 20 is a video game produced by Electronic Arts, the raw data of different ratings and player information are given by EA’s developers and the creator of this dataset just compiled them together into one dataset.  We found this dataset on Kaggle, and it belongs to a Kaggle user ‘Fateh Ghader’, but it is not revealed if he collected and compiled the data himself. 

There are 16,042 total observations in our dataset and each one represents an outfield player in FIFA with his details like club and position and his different ratings. Below is a table of several observation(player) with selected variables that we used in our project：

```{r, echo=FALSE, warning=FALSE,message=F}

FIFA_20 <- read_csv("FIFA_20.csv")
table<-FIFA_20
#table
tablehead<-table%>% select(name,position,age,height_cm,shooting,passing,dribbling,defending,physic,fk_accuracy,stamina,penalties,standing_tackle,sliding_tackle,skill_moves)%>%
  rename(Age=age, "Height in cm"="height_cm",Shooting=shooting, Passing=passing, Dribbling=dribbling, Defending=defending, Physic=physic, "FreeKick Accuracy"=fk_accuracy, Stamina=stamina, Penalties=penalties, "Standing Tackles"="standing_tackle","Sliding Tackles"="sliding_tackle","Skills and Moves"="skill_moves", Position=position)

tablehead2<-head(tablehead)

kbl(tablehead2) %>%
  kable_styling(bootstrap_options = "striped", font_size = 7)
```
```{r, echo=FALSE}
#table
graphss<- table %>%
  select(age,height_cm,shooting,passing,dribbling,defending,physic,fk_accuracy,stamina,penalties,standing_tackle,sliding_tackle)%>%
  rename(Age=age, "Height in cm"="height_cm",Shooting=shooting, Passing=passing, Dribbling=dribbling, Defending=defending, Physic=physic, "FreeKick Accuracy"=fk_accuracy, Stamina=stamina, Penalties=penalties, "Standing Tackles"="standing_tackle","Sliding Tackles"="sliding_tackle")%>%
  keep(is.numeric)%>%
  gather()%>%
  ggplot(aes(value, color= key))+
    geom_density()+xlab("Value")+ylab("Density")+ggtitle("Continuous Variables")
#graphss


graphssf<- table %>%
  select(age,height_cm,shooting,passing,dribbling,defending,physic,fk_accuracy,stamina,penalties,standing_tackle,sliding_tackle)%>%
  rename(Age=age, "Height in cm"="height_cm",Shooting=shooting, Passing=passing, Dribbling=dribbling, Defending=defending, Physic=physic, "FreeKick Accuracy"=fk_accuracy, Stamina=stamina, Penalties=penalties, "Standing Tackles"="standing_tackle","Sliding Tackles"="sliding_tackle")%>%
  keep(is.numeric)%>%
  gather()%>%
  ggplot(aes(value, color= key))+facet_wrap(~ key, scales = "free") +
    geom_density()+xlab("Value")+ylab("Density")+ggtitle("Continuous Variables")
graphssf

graphscat<- table%>%
  select(skill_moves, position)%>%
  rename("Skills and Moves"="skill_moves", Position=position)%>%
  gather()%>%
  ggplot(aes(value))+facet_wrap(~ key, scales = "free") +
    geom_bar(color ="blue", fill="blue")+ theme_minimal()+xlab("Value")+ylab("Count")+ggtitle("Categorical Variables")

graphscat
  
```

Even though ratings like shooting, passing, and dribbling seemed quite intuitive; ratings like finishing, composure and standing tackle require extra clarifications for someone unfamiliar with soccer. Finishing is quite similar to shooting, with the difference being shooting indicates generally how well a player shoots and finishing indicates specifically how good a player is sending the ball to the net when he’s very close to the goal. Free kick accuracy (fk_accuracy) indicates the percent of free kicks a player takes that actually result in a goal for his team. Standing tackle indicates how well a player is when trying to retake possession from opponent players in a standing form instead of typical sliding tackle.






# RESULTS

# Question 1 
```{r,include=FALSE}
table<-read.csv("FIFA_20.csv")
```

```{r,include=FALSE}
table2<-table%>%select("age":"sliding_tackle")
mod1=lm(composure~.,data=table2)
```

```{r,include=FALSE}
table3<-table2%>%select(-composure)
summary(mod1)
colnames(table3)[summary(mod1)$coefficients[-1,4]<0.01]


table3=table3%>%select(age,height_cm,shooting,passing,dribbling,defending,physic,fk_accuracy,stamina,penalties,standing_tackle,sliding_tackle)
table3=cbind(table3,composure=table2$composure)

```

```{r,include=FALSE}
mod<-function(data,i){
  mod1=lm(composure~poly(age,i)+poly(height_cm,i)+poly(shooting,i)+poly(passing,i)+poly(dribbling,i)+poly(defending,i)+poly(physic,i)+poly(fk_accuracy,i)+poly(stamina,i)+poly(penalties,i)+poly(standing_tackle,i)+poly(sliding_tackle,i),data=data)
  return (mod1)
}

table4=table3%>%crossv_kfold(10)

result<-table4%>%mutate(tr.model=map(train,mod,i=1))%>%
  mutate(predict=map2(test,tr.model,~augment(.y,newdata=.x)))%>%
  select(predict)%>%unnest(cols=c(predict))

rmse<-function(x,y){
  resid=x-y
  mse=mean(resid^2,na.rm=T)
  rmse=sqrt(mse)
  return(rmse)
}

mse<-function(x,y){
  resid=x-y
  mse=mean(resid^2,na.rm=T)
  return(mse)
}


mae<-function(x,y){
  resid=x-y
  return(mean(abs(resid)))
}


bias.func=function(x,y){
  res=x-y
  bias=mean(res,na.rm=T)
  return(bias)
}
```

```{r,include=FALSE}
array=rep(NA,12)
for (i in 1:12){
  result<-table4%>%mutate(tr.model=map(train,mod,i=i))%>%
  mutate(predict=map2(test,tr.model,~augment(.y,newdata=.x)))%>%
  select(predict)%>%unnest(cols=c(predict))
  array[i]=mae(result$composure,result$.fitted)
}
```


```{r}
min_i=which.min(array)
#min_i
ggplot(tibble(array))+geom_line(aes(1:12,array),color="lightskyblue2",size=2)+
  theme_minimal() +
  xlab("Choice of i") +
  ylab("MSE") +
  theme(text=element_text(size=10))
```

```{r,include=FALSE}
result<-table4%>%mutate(tr.model=map(train,mod,i=min_i))%>%
  mutate(predict=map2(test,tr.model,~augment(.y,newdata=.x)))%>%
  select(predict)%>%unnest(cols=c(predict))
result
```

```{r,include=FALSE}
table5=cbind(name=table$name,nation=table$nationality,club=table$club,table3,pred_composure=result$.fitted)
```

```{r,include=FALSE}
head(table5)
table5=table5%>%mutate(resid=pred_composure-composure)
```




```{r,include=FALSE}
DATA2<-table%>%select("age":"sliding_tackle")
y= DATA2$composure
X=model_matrix(DATA2,composure~.*.)[,-1]
var.names=names(X)
dim(X)
head(X)
```

```{r,include=FALSE}
set.seed(216)
cvmod.0=cv.glmnet(y=y,x=as.matrix(X),alpha=0)
set.seed(216)
cvmod.25=cv.glmnet(y=y,x=as.matrix(X),alpha=0.25)
set.seed(216)
cvmod.5=cv.glmnet(y=y,x=as.matrix(X),alpha=0.5)
set.seed(216)
cvmod.75=cv.glmnet(y=y,x=as.matrix(X),alpha=0.75)
set.seed(216)
cvmod.1=cv.glmnet(y=y,x=as.matrix(X),alpha=1)
cvmod.0
CV.0.ERROR=cvmod.0$cvm[which(cvmod.0$lambda==cvmod.0$lambda.1se)]
CV.25.ERROR=cvmod.25$cvm[which(cvmod.25$lambda==cvmod.25$lambda.1se)]
CV.5.ERROR=cvmod.5$cvm[which(cvmod.5$lambda==cvmod.5$lambda.1se)]
CV.75.ERROR=cvmod.75$cvm[which(cvmod.75$lambda==cvmod.75$lambda.1se)]
CV.1.ERROR=cvmod.1$cvm[which(cvmod.1$lambda==cvmod.1$lambda.1se)]

MOD.RESULT=tibble(alpha=c(0,0.25,0.5,0.75,1),
                  lambda=c(cvmod.0$lambda.1se,cvmod.25$lambda.1se,
                           cvmod.5$lambda.1se,cvmod.75$lambda.1se,
                           cvmod.1$lambda.1se),
                  CV.Error=c(CV.0.ERROR,CV.25.ERROR,CV.5.ERROR,
                             CV.75.ERROR,CV.1.ERROR))
print(MOD.RESULT)
```

```{r,include=FALSE}
best.alpha=MOD.RESULT$alpha[which.min(MOD.RESULT$CV.Error)]
best.lambda=MOD.RESULT$lambda[which.min(MOD.RESULT$CV.Error)]

best.mod=glmnet(y=y,x=as.matrix(X),nlambda=1,lambda=best.lambda,alpha=best.alpha)
best.coef=as.tibble(as.matrix(coef(best.mod)))
best.coef2=best.coef %>% 
              mutate(Parameter=c("Intercept",var.names)) %>%
              rename(Estimate=s0) %>%
              select(Parameter,Estimate)
nonzero.best.coef=best.coef2 %>%
                    filter(Estimate!=0)
print(nonzero.best.coef,n=1e3)



DATA2$composure.pred=predict(best.mod,newx=as.matrix(X))




```



For question 1,"Which model and its variables best predict the variable composure." We look variables age, weight, height and other metrics assessing the skills of a player in total of 17 variables and we use two modeling techniques: Polynomial model and Shrinkage model. Since we want to simulate these two models in the same standards, we both fit them by using MSE
test to return the most accurate parameters. 

Polynomial linear model:
First we choose the variables according to their t values, We look at the variables with the probability of t value falls under 0.01 to be significant. So we eventually have 12 variables out of 17. Then we use cross validation with 10 folds to split the data into 10 training and testing sets, and compute the predicted values. We also use for loops from 1 to 12 to choose the best exponent for all variables. And we compare them by using MSE test. It terms out power term 9 returns the lowest MSE. Then we apply the exponent to our method and return the list of predicted values for composure. 

Shrinkage Method:
Second, we try to use shrinkage method to predict composure. We first split the data into two matrices, one column matrix of composure and matrix of 17 variables and their interaction. Then, we use set alpha to five values and apply cv.glmnet to find each alpha's lowest prediction error by MSE and its corresponding lambda. We compare these five results and choose the one with lowest MSE. It terms out the model is Lasso Regression with alpha equals to 1 and lambda equals 0.004. We use this model to choose the variables and predict the composure. It shrinks over 14000 variables into 70. And only choose 8 non-interacted variables out of 17. 

we also fit a scatter plot with actual values in x axis and predicted values in y axis. And a reference line. Both of models have points closely scattered around the reference line. 

```{r,echo=FALSE}
ggplot(result,aes(composure,.fitted))+geom_point()+geom_abline(slope=1,intercept=0,size=2,color="red",linetype="dashed")+
  ylab("Predicted composure")+theme_bw()+xlab("Actual Composure")+ggtitle("Polynomial Model")

ggplot(DATA2) +
  geom_point(aes(x=composure,y=composure.pred)) +
  geom_abline(intercept=0,slope=1,linetype="dashed",size=2,color="red") +
  theme_bw() +
  ylab("Predicted Composure") +
  xlab("Actual Composure")+ggtitle("Shrinkage Model")



```

We also fit the frequency models for the absolute values of residuals. Two plots are very similar and both have their peak around 2 to 3. 

```{r ,warning=FALSE,echo=FALSE,message=FALSE}
ggplot(result,aes(abs(.fitted-composure)))+geom_freqpoly(color="lightskyblue2",size=2)+theme_bw()+ylab("Frequency")+xlab("Residuals")+ggtitle("Polynomial Model")

ggplot(DATA2) +
  geom_freqpoly(aes(x=abs(composure.pred-composure)),color="lightskyblue2",size=2) +
  theme_bw() +
  xlab("Residuals") +
  ylab("Frequency")+ggtitle("Shrinkage Model")


```

Then we compare these two models by RMSE and MAE test, it terms out shrinkage did a slightly better job in both of methods. The tibble quantitatively shows that these models are very similar in results. But we do have a bias in polynomial regression, since we set the power term on each variable to the same instead of running multiple for loops to find the best exponent for each variable. So the best predicting models might have lower prediction errors but it would be time-consuming for the computer to result in the best consequence and it does not consider the interaction terms of different variables. Rather, the shrinkage model is more easy to generate and more accurate by considering the interaction variables. 

```{r,echo=FALSE}
rmsetable<-matrix(c(5.64,5.49,4.47,4.33), ncol=2, byrow=TRUE)
colnames(rmsetable)<-c("Polynomial Model","Shrinkage Model")
rownames(rmsetable)<-c("RMSE", "MAE")
kbl(rmsetable) %>%
  kable_styling(bootstrap_options = "striped", font_size = 7)

#tibble2<-data.frame(Polynomial_Model=c(round(rmse(result$composure,result$.fitted),2),                        round(mae(result$composure,result$.fitted),2)),                       Shrinkage_Model=c(round(rmse(DATA2$composure,DATA2$composure.pred),2),round(mae(DATA2$composure,DATA2$composure.pred),2)))
#rownames(tibble2)=c("RMSE","MAE")
#tibble2
```
# Question 2
In order to answer "Can we predict the wage of a player by looking at their skill level, position, defending rating, and their shooting rating?" Below we can see a boxplot show the distribution of wages for the players. The plot shows how the wages have many outliers. However, because there were so many outliers we decided not to remove them from our data as we are still interested in predicting the high valued players.


```{r, echo=FALSE, warning=FALSE}
ggplot(data=table)+geom_boxplot(aes(y=wage_eur))+ theme_minimal()+ylab("Wage in Euros")+ ggtitle("Distribution of Wages")
```

We started with a linear model using all of the variables listed. We used cross validation with 80% of the data in the training set. We factored the variable Skills (skill_moves), as it is rated on a scale from 1 to 5. We choose not to factor the other rated variables as they are rated on a scale from 1 to 100 and due to the large amount of categories, we can reasonably treat it as continuous. Since all of the p-values were less than .01 we kept all variables for our analysis. This model had an RMSE of 17514.57, and an Adjusted R-squared of .3071. 


Next we tried another linear model using the interaction between variables in order to improve the model. Taking the interaction of position and all the other variables, and Skill rating and all the other variables. We used the same training and test set from the previous linear model. This model had a RMSE of 16805.08. This also gave us an Adjusted R-Squared of .3828, which is an improvement. However, the RMSE is still high so in order to get a improved model we next tried a polynomial model.
```{r, echo=FALSE}
table2x<-table %>% select(wage_eur,work_rate,position,skill_moves,shooting,defending,fk_accuracy)
mod1x=lm(wage_eur~position+factor(skill_moves)+shooting+defending,data=table2x)
```

```{r, echo=FALSE}
table3x<-table2x%>%select(-wage_eur)
#summary(mod1x)
#colnames(table3x)[summary(mod1x)$coefficients[-1,4]<0.01]


table3x=table3x%>%select(work_rate,position,skill_moves,shooting,defending,fk_accuracy)
table3x=cbind(table3x,wage_eur=table2x$wage_eur)
#table3x

rmse<-function(x,y){
  resid=x-y
  mse=mean(resid^2,na.rm=T)
  rmse=sqrt(mse)
  return(rmse)
}

mse<-function(x,y){
  resid=x-y
  mse=mean(resid^2,na.rm=T)
  return(mse)}

mae<-function(x,y){
  resid=x-y
  return(mean(abs(resid)))
}
```

```{r, echo=FALSE}

set.seed(101) # Set Seed so that same sample can be reproduced in future also

sample.game <- sample.int(n = nrow(table), size = floor(.80*nrow(table)), replace = F)
trainx <- table[sample.game, ]
testx  <- table[-sample.game, ]

modellin<-lm(wage_eur~position+factor(skill_moves)+shooting+defending+ position*shooting+position*defending,data=trainx)
#summary(modellin)


tablexxxx<- testx%>% mutate(predlinw=predict(modellin,testx))


#rmse(testx$wage_eur,tablexxxx$predlinw)
#mse(testx$wage_eur,tablexxxx$predlinw)
#mae(testx$wage_eur,tablexxxx$predlinw)
```

```{r, echo=FALSE}

  modelinx=lm(wage_eur~position+factor(skill_moves)+shooting+defending+ position*shooting+position*defending+factor(skill_moves)*position+ factor(skill_moves)*defending+factor(skill_moves)*shooting,data=trainx)
  
#summary(modelinx)

tablexxxx<- testx%>% mutate(predlin=predict(modelinx,testx))


#rmse(testx$wage_eur,tablexxxx$predlin)
#mse(testx$wage_eur,tablexxxx$predlin)
#mae(testx$wage_eur,tablexxxx$predlin)
```


```{r, echo=FALSE}
modx<-function(data,i){
 mod1x=lm(wage_eur~(position)+factor(skill_moves)+poly(shooting,i)+poly(defending,i), data=data)
  return (mod1x)
}

table4x=table3x%>%crossv_kfold(10)

resultx<-table4x%>%mutate(tr.modelx=map(train,modx,i=1))%>%
  mutate(predict=map2(test,tr.modelx,~augment(.y,newdata=.x)))%>%
  select(predict)%>%unnest(cols=c(predict))


```

```{r, echo=FALSE}
arrayx=rep(NA,12)
for (i in 1:12){
  resultx<-table4x%>%mutate(tr.modelx=map(train,modx,i=i))%>%
  mutate(predictx=map2(test,tr.modelx,~augment(.y,newdata=.x)))%>%
  select(predictx)%>%unnest(cols=c(predictx))
  arrayx[i]=mae(table2x$wage_eur,resultx$.fitted)
}

```

Making a polynomial model we followed a similar process to our first question. We used our training and testing sets made from a 10 folds cross validation from our first question. We then made a function to make models using our variables. Again we factor the skill level, but we also used the polynomial function to put the other continuous variables to the i th power.  We choose i by finding where it has the lowest MAE. We found that i should be equal to 5 in order to make the model with the lowest MAE at 12590.38. However the RMSE is still very high at 25153.22.



```{r, echo=FALSE}
min_ix=which.min(arrayx)
#min_ix
#min(arrayx)
ggplot(tibble(arrayx))+geom_line(aes(1:12,arrayx),color="lightskyblue2",size=2)+
  theme_minimal() +
  xlab("Choice of i") +
  ylab("MAE") +
  theme(text=element_text(size=10))
  



```


```{r, echo=FALSE}
resultx<-table4x%>%mutate(tr.modelx=map(train,modx,i=min_ix))%>%
  mutate(predictx=map2(test,tr.modelx,~augment(.y,newdata=.x)))%>%
  select(predictx)%>%unnest(cols=c(predictx))
```

```{r, echo=FALSE}
table5x=cbind(name=table$name,nation=table$nationality,club=table$club,table3x,pred_income=resultx$.fitted)
```

```{r, echo=FALSE}
#head(table5x)
table5x=table5x%>%mutate(resid=wage_eur-pred_income)

```

```{r, echo=FALSE}
#ggplot(table5x,aes(x=wage_eur,y=resid))+geom_point()+geom_abline(slope=0, color="black")+theme_minimal()+ylab("residuals")+xlab("Wage in Euros")#ylim(c(-50,50))
ggplot(table5x,aes(x=wage_eur,y=pred_income))+geom_point()+geom_abline(slope=1,intercept=0)+xlab("Wage in Euros")+ylab("Predicted Wage")


mse(table2x$wage_eur,table5x$pred_income)
```

```{r, echo=FALSE}
rmsetable2<-matrix(c(17514.57,16805.08,25153.22,8868.928, 8222.876,12590.38), ncol=3, byrow=TRUE)
colnames(rmsetable2)<-c("Linear Model","Linear Model with Interaction","Polynomial Model")
rownames(rmsetable2)<-c("RMSE", "MAE")

kbl(rmsetable2) %>%
  kable_styling(bootstrap_options = "striped", font_size = 7)
```

Looking at the results of our analysis we can say that our linear model with interaction is best for predicting wage. However, we think there is too much error in our models to accurately predict wage for the FIFA players.





# CONCLUSION

In analyzing and modeling the FIFA 20 data, we wanted to understand which variables are adequate predictors of other variables. For our first question specifically, we wanted to make out which variables were adequate predictors of a player’s composure.  In answering our first question, we found that all of the variables used in the shrinkage model adequately predicted composure. For our second question, we sought out to identify whether or not specific variables, skill level, position, defending rating, and shooting rating were adequate predictors of a player’s income. For this question, the model was hard to predict because there were many outliers that skewed the data, due in large part to the fact that highly skilled players have wages that are much larger than the average player, who doesn’t make much. As a result, we concluded that none of the variables we looked at were adequate predictors of a player’s wage. Because income was so skewed, in the future we could improve this with access to an additional variable, such as the team budget for the wages, or by removing the outliers completely and focusing only on the common wages. 

Overall, the premise and results of both of our questions are important in the real world as FIFA bases its players off of actual soccer players. As a result, learning which variables adequately predict others can be helpful to those who play FIFA, its creators and anyone interested in the statistics and properties of the actual soccer players that the game is based on. Understanding a player’s strengths, weaknesses and skills allows for those playing the game to strategically choose their players. Similarly, this understanding can help coaches and other members of the actual soccer teams adequately assess their players.

----------------------------------------------------


