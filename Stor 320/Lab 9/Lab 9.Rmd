---
title: "Lab 9: Modeling Basics"
author: "FIRSTNAME LASTNAME"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=F)
options(scipen=999)
library(tidyverse)
library(modelr)
library(broom)
```

# Introduction

In this lab, you will build predictive models for board game ratings. The dataset below was scraped from [boardgamegeek.com](www.boardgamegeek.com) and contains information on the top 4,999 board games. Below, you will see a preview of the data

```{r}
bgg<-read.csv("bgg.csv")
bgg2=bgg[,c(4:13,15:20)]
head(bgg2)
```

You will need to modify the code chunks so that the code works within each of chunk (usually this means modifying anything in ALL CAPS). You will also need to modify the code outside the code chunk. When you get the desired result for each step, change `Eval=F` to `Eval=T` and knit the document to HTML to make sure it works. After you complete the lab, you should submit your HTML file of what you have completed to Sakai before the deadline.

# Board Game Analysis

### Q1

There are 16 variables and we want to create some more. Create a new dataframe called $bgg3$ where you use the mutate function to create the following variables:

- *duration=2018-year+1*
- *vote.per.year=num_votes/duration*
- *own.per.year=owned/duration*
- *player.range=max_players-min_players*
- *log_vote=log(num_votes+1)*
- *log_own=log(owned+1)*
- *diff_rating=avg_rating-geek_rating*

```{r,eval=T}
bgg3<-bgg2%>%mutate(duration=2018-year+1,
                    vote.per.year=num_votes/duration,
                    own.per.year=owned/duration,
                    player.range=max_players-min_players,
                    log_vote=log(num_votes+1),
                    log_own=log(owned+1),
                    diff_rating=avg_rating-geek_rating)
head(bgg3)
```

Question: In complete sentences, what is the purpose of adding 1 for the log transformed variables?
You can't have log0

Question: In complete sentences, what is the purpose of adding 1 in the creation of the year variable?
include the year 2018, so we need to minus the two years and also add one to it. 


### Q2

We hypothesize the geek rating increases when the number of votes increases and/or the ownership increases. Create four scatter plots showing the association with geek_rating and the following variables:

- *num_votes*
- *owned*
- *log_vote*
- *log_own*


```{r,eval=F}
ggplot(bgg3,aes(x=num_votes,y=geek_rating))+geom_point()
ggplot(bgg3,aes(x=owned,y=geek_rating))+geom_point()
ggplot(bgg3,aes(x=log_vote,y=geek_rating))+geom_point()
ggplot(bgg3,aes(x=log_own,y=geek_rating))+geom_point()

```

Question: In complete sentences, describe how the relationship changes when you take the log of the independent variable.
the positive linear relationship become more obvious and it sketch outside. Since logy actually decentralizes the values.


### Q3

Randomly sample approximately 80\% of the data in `bgg3` for a training dataset and the remaining will act as a test set. Call the training dataset `train.bgg` and the testing dataset `test.bgg`.

```{r,eval=F}
set.seed(216)

sample.in=sample(1:dim(bgg3)[1],size=floor(0.8*dim(bgg3)[1]))
 train.bgg=bgg3[sample.in,]
 test.bgg=bgg3[-sample.in,]


#train.bgg<-filter(bgg4,Set=="Train")
#test.bgg<-filter(bgg4,Set=="Test")
train.bgg
test.bgg
```



### Q4

Now, we want to fit models to the training dataset. Use the `lm()` function to create 3 model objects in R called `lm1`, `lm2`, `lm3` based on the following linear models, respectively:

- $\textrm{geek_rating}=\beta_0+\beta_1 log(\textrm{num_votes})+\epsilon$
- $\textrm{geek_rating}=\beta_0+\beta_1 log(\textrm{owned})+\epsilon$
- $\textrm{geek_rating}=\beta_0+\beta_1 log(\textrm{owned})+ \beta_2 \textrm{vote.per.year}+ \beta_3 \textrm{weight} + \epsilon$

```{r,eval=T}
lm1 = lm(geek_rating~log_vote,data=train.bgg)
lm2 = lm(geek_rating~log_own,data=train.bgg)
lm3 = lm(geek_rating~log_own+vote.per.year+weight,data=train.bgg)
```

### Q5

Add predictions and residuals for all 3 models to the test set. Create a new data frame called `test.bgg2` and give all your predictions and residuals different names. Use the `str()` function to show these variables were created


```{r,eval=F}
test.bgg2<-test.bgg%>%add_predictions(lm1,var="pred1")
test.bgg2<-test.bgg2%>%add_predictions(lm2,var="pred2")
test.bgg2<-test.bgg2%>%add_predictions(lm3,var="pred3")

test.bgg2<-test.bgg2%>%add_residuals(lm1,var="resi1")
test.bgg2<-test.bgg2%>%add_residuals(lm2,var="resi2")
test.bgg2<-test.bgg2%>%add_residuals(lm3,var="resi3")


str(test.bgg2)
```


### Q6

Create a function called `MAE.func()` that returns the mean absolute error of the residuals and test your function on the vector called `test`

Solution 1:
```{r,eval=F}
test=c(-5,-2,0,3,5)
MAE.func<-function(x){
  mae=mean(abs(x),na.rm=T)
  return(mae)
}


MAE.func(test)
```

### Q7

Use your function to calculate the mean absolute error based on the residuals to calculate the out-of-sample MAE. Make sure you display the mean absolute error from these different models in your output.

```{r,eval=F}
MAE.func(test.bgg2$resi1)
MAE.func(test.bgg2$resi2)
m<-MAE.func(test.bgg2$resi3)
```

Question: Which model does the best job at predicting the geek rating of these board games?
The third model.

### Q8

For the third model, use 10-fold cross-validation and measure the mean absolute error. Print this measure of error out.

```{r,eval=F}
test.bgg3<-test.bgg%>%crossv_kfold(10)
train.model.func=function(data){
  mod=lm(geek_rating~log_own+vote.per.year+weight,data=data)
  return(mod)
}
test.bgg4= test.bgg3 %>% mutate(tr.model=map(train,train.model.func))
test.bgg5<-test.bgg4%>% mutate(predict=map2(test,tr.model,~augment(.y,newdata=.x))) %>%
          select(predict) %>%
         unnest()

abs_error=mean(abs(test.bgg5$geek_rating-test.bgg5$.fitted),na.rm=T)

abs_error
abs(abs_error-m)
```

Question: What is the absolute difference between the out-of-sample mean absolute error measured using a test set and the mean absolute error measured using cross validation? When you type your answer in complete sentences use inline R code to calculate the absolute difference and input it directly into your sentence.

The difference is 0.00443.







